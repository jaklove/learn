1.进程的概念：
  我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会⽣成⼆进制可执⾏⽂件，当我们运⾏这个可执行文件后，它会被装载到内存中
,接着 CPU 会执行程序中的每条指令，那么这个运行中的程序，就被称为「进程」。

2.并发的概念：虽然单核的 CPU 在某个瞬间，只能运行1个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并发的错觉，实际上这是并发。

3.进程的状态？
  在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。 
  .运行状态：该时刻进程占用cpu
  .就绪状态：可运行，由于其他进程处于运行状态而暂时停止运行
  .阻塞状态：该进程正在等待某一事件发生(如等待输入/输出操作的完成)而暂时停止运行，这时，即使给它cpu控制权，它也无法运行。
  
  
  进程的状态跃迁：
  1.创建状态：一个新进程被创建时的第一个状态
  2.创建状态 -> 就绪状态: 当进程被创建完并完成初始化后，一切就绪准备运行时,变为就绪状态,这个过程是很快的.
  3.就绪态 -> 运行状态：  处于就绪状态的进程被操作系统的进程调度器选中后，就分配给CPU正式运行该进程
  4.运行状态 -> 结束状态: 当进程已经运行完成或出错时，会被操作系统作结束状态处理
  5.运行状态 -> 就绪状态： 处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把进程变为就绪态，
    接着从就绪态选中另外一个进程运行
  6.运行状态 -> 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I/O 事件	
  7.阻塞状态 -> 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态； 

  如果果有大量处于阻塞状态的进程，进程可能会占着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，
被阻塞状态的进程占着物理内存就一种浪费物理内存的行为，所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，
等需要再次运行的时候，再从硬盘换入到物理内存，那么就需要一个新的状态来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟
阻塞状态是不一样，阻塞状态是等待某个事件的返回。
  
  挂起状态可以分为两种：
   .阻塞挂起状态:进程在外存(硬盘)并等待某个事件的出现
   .就绪挂起状态:进程在外存(硬盘),但只要进入内存，即刻立刻运行；
   
  导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：
   1.通过 sleep 让进程间歇性挂起，其⼯作原理是设置一个定时器，到期后唤醒进程.
   2.用户希望挂起⼀个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程；
   
   
  在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的，PCB 是进程存在的唯一标识，这意味着1个进程的存在，必然会有一个 PCB，如果进程消失
了，那么 PCB 也会随之消失。
   PCB包含进程标识符(标识各个进程，每个进程都有1个并且唯一的标识符)、用户标识符(进程归属的用户，用户标识符主要为共享和保护服务)
   
   进程控制和管理信息：
    1.进程当前状态
	2.进程优先级：进程抢占 CPU 时的优先级；
	
   资源分配清单:
    1.有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。   
    
   CPU 相关信息：
    CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB中，以便进程重新执行时，能从断点处继续执行
	
每个pcb如何组织的？
   1.通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列，将所有处于就绪状态的进程链在一起，称为就绪队列，把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列。	
   2.另外，对于运行队列在单核 CPU 系统中则只有1个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。
   
   
创建进程相关知识？
   操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止
其所有的子进程。
   
 
创建进程:
  1.为新进程分配一个唯一的进程标识号,并申请一个空白的PCB,PCB是有限的,若申请失败则创建失败； 
  2.为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源。
  3.初始化PCB；
  4.如果进程的调度队列能够接纳新进程，那就将进程插⼊到就绪队列，等待被调度运行。
  
终止进程:
  进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。
  1.查找需要终⽌的进程的 PCB；
  2.如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程  
  3.如果其还有子进程，则应将其所有子进程终止
  4.将该进程所拥有的全部资源都归还给父进程或操作系统 
  5.将其从PCB所在队列中删除   
  
  
阻塞进程
  当进程需要等待某⼀事件完成时，它可以调用阻塞语句自己阻塞等待。而一旦被阻塞等
待，它只能由另1个进程唤醒。  
  阻塞进程的过程如下：
    1.找到将要被阻塞进程标识号对应的 PCB
	2.如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行
	3.将该PCB插到到阻塞队列中去；
  
唤醒进程  
    1.运行」转变为「阻塞」状态是由于进程必须等待某件事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的.
	2.如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出
现时，才由发现者进程用唤醒语句叫醒它
    
唤醒进程的过程如下：
   1.在该事件的阻塞队列中找到相应进程的PCB
   2.将其从阻塞队列中移出，并置其状态为就绪状态
   3.把该 PCB 插⼊到就绪队列中，等待调度程序调度；
     
进程的阻塞和唤醒是⼀对功能相反的语句，如果某个进程调⽤了阻塞语句，则必有⼀个与之
对应的唤醒语句。

进程的上下文切换
   1.各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在
CPU执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。	 

CPU上下文切换：
   CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存(缓存)。再来，程序计数器则是⽤来存储 CPU 正在执⾏的指令位置、或者即将执行的下一条指令位置，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位
置,所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前所必须依赖的环境，这些环境就叫做 CPU上下文。CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起
来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU运行时，CPU 会重新
加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续。


进程的上下文切换到底是切换什么呢？
  进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。通常，会把交换的信息保存在进程的 PCB，当要运行另外1个进程的时候，我们需要从这个
进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，


发生进程上下文切换有哪些场景？   
   1.为了保证所有进程可以得到公平调度，CPU 时间被划分为⼀段段的时间⽚，这些时间片
再被轮流分配给各个进程。这样，当某个进程的时间⽚耗尽了，进程就从运行状态变为就
绪状态，系统从就绪队列选择另外一个进程运行；
  2.进程在系统资源不足（如内存不足）时，要等到资源满足后才可以运行，这个时候进程
也会被挂起，并由系统调度其他进程运行
  3.当进程通过睡眠函数sleep这样的方法将自己主动挂起时，自然也会重新调度；
  4.当有优先级更⾼的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。
  5.发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序


1.线程
   在早期的操作系统中都是以进程作为独⽴运⾏的基本单位，直到后⾯，计算机科学家们⼜提出了更⼩的能独⽴运⾏的基本单位，也就是线程。
直白点线程是进程当中的⼀条执⾏流程，同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每个线程各⾃都有⼀套独⽴的寄存器和栈，
这样可以确保线程的控制流是相对独⽴的。

  线程有哪些优点：
    1.一个进程中可以同时存在多个线程；
    2.各个线程之间可以并发执⾏；
    3.各个线程之间可以共享地址空间和⽂件等资源；

  线程有哪些缺点：
    1.当进程中的⼀个线程崩溃时，会导致其所属进程的所有线程崩溃


  线程与进程的⽐较如下：
    1.进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；
    2.进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
    3.线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
    4.线程能减少并发执⾏的时间和空间开销；

  对于，线程相⽐进程能减少开销，体现在:
    1.线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们.
    2.线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多;
    3.同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共
      享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚
      表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的
    4.于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了；

线程的上下⽂切换?
    在前⾯我们知道了，线程与进程最⼤的区别在于：线程是调度的基本单位，⽽进程则是资源拥有的基本单位,所以，所谓操作系统的任务调度，实际上的调度对象是线程，
⽽进程只是给线程提供了虚拟内存、全局变量等资源。

对于线程和进程，我们可以这么理解：
    1.当进程只有⼀个线程时，可以认为进程就等于线程；
    2.当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下⽂切换时是不需要修改的；
    3.另外，线程也有⾃⼰的私有数据，⽐如栈和寄存器等，这些在上下⽂切换时也是需要保存的

这还得看线程是不是属于同⼀个进程:
     1.当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
     2.当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；
     3.因此线程的上下文切换相比进程开销要小很多。

线程的实现
     1.⽤户线程（User Thread）：在⽤户空间实现的线程，不是由内核管理的线程，是由⽤户态的线程库来完成线程的管理；
     2.内核线程（Kernel Thread）：在内核中实现的线
     3.轻量级进程（LightWeight Process）：在内核中来⽀持⽤户线程；

⽤户线程如何理解？存在什么优势和缺陷？
     ⽤户线程是基于⽤户态的线程管理库来实现的，那么线程控制块（Thread Control Block,TCB）也是在库⾥⾯来实现的，对于操作系统⽽⾔是看不到这个 TCB 的，它只能看到整个进程的 PCB。
所以，⽤户线程的整个线程管理和调度，操作系统是不直接参与的，⽽是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等。


⽤户线程的优点：
     1.每个进程都需要有它私有的线程控制块（TCB）列表，⽤来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由⽤户级线程库函数来维护，可⽤于不⽀持线程技术的操作系统；
     2.⽤户线程的切换也是由线程库函数来完成的，⽆需⽤户态与内核态的切换，所以速度特别快；

⽤户线程的缺点：
    1.由于操作系统不参与线程的调度，如果⼀个线程发起了系统调⽤⽽阻塞，那进程所包含的⽤户线程都不能执⾏了。
    2.当⼀个线程开始运⾏后，除⾮它主动地交出 CPU 的使⽤权，否则它所在的进程当中的其他线程⽆法运⾏，因为⽤户态的线程没法打断当前运⾏中的线程，
      它没有这个特权，只有操作系统才有，但是⽤户线程不是由操作系统管理的。
    3.由于时间⽚分配给进程，故与其他进程⽐，在多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢；

内核线程是由操作系统管理的，线程对应的 TCB ⾃然是放在操作系统⾥的，这样线程的创建、终⽌和管理都是由操作系统负责。

内核线程的优点：
   1.在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并不会影响其他内核线程的运⾏；
   2.分配给线程，多线程的进程获得更多的 CPU 运⾏时间；

内核线程的缺点：
   1.在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如PCB和TCB；
   2.线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤；

调度原则：
  原则⼀：如果运⾏的程序，发⽣了 I/O 事件的请求，那 CPU 使⽤率必然会很低，因为此时进程在阻塞等待硬盘的数据返回，
这样的过程，势必会造成 CPU 突然的空闲。所以，为了提⾼CPU 利⽤率，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择⼀个进程来运⾏。
  原则⼆：有的程序执⾏某个任务花费的时间会⽐较⻓，如果这个程序⼀直占⽤着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。
所以，要提⾼系统的吞吐率，调度程序要权衡⻓任务和短任务进程的运⾏完成数量。
  原则三：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运⾏时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越⼩越好，
如果进程的等待时间很⻓⽽运⾏时间很短，那周转时间就很⻓，这不是我们所期望的，调度程序应该避免这种情况发⽣。
  原则四：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执⾏。
所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。
  原则五：对于⿏标、键盘这种交互式⽐较强的应⽤，我们当然希望它的响应时间越快越好，否则就会影响⽤户体验了。
所以，对于交互式⽐较强的应⽤，响应时间也是调度程序需要考虑的原则。


根据上面调度的原则，总结如下:
  CPU 利⽤率：调度程序应确保 CPU 是始终匆忙的状态，这可提⾼ CPU 的利⽤率；
  系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，⻓作业的进程会占⽤较⻓的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
  周转时间：周转时间是进程运⾏和阻塞时间总和，⼀个进程的周转时间越⼩越好；
  等待时间：这个等待时间不是阻塞状态的时间，⽽是进程处于就绪队列的时间，等待的时间越⻓，⽤户越不满意；
  响应时间：⽤户提交请求到系统第⼀次产⽣响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。

调度算法
  1.最简单的⼀个调度算法，就是⾮抢占式的先来先服务（First Come First Seved, FCFS）算法了，每次从就绪队列选择最先进⼊队列的进程，
     然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运⾏。
  2.最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运⾏时间最短的进程来运⾏，这有助于提⾼系统的吞吐量。
  3.⾼响应⽐优先（Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和⻓作业。(优先权=(等待时间+要求服务时间)/要求服务时间)
  4.最古⽼、最简单、最公平且使⽤最⼴的算法就是时间⽚轮转（Round Robin, RR）调度算法。(每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。)
  5.希望调度程序能从就绪队列中选择最⾼优先级的进程进⾏运⾏，这称为最⾼优先级（Highest Priority First，HPF）调度算法。
    进程的优先级可以分为，静态优先级和动态优先级：
    1.静态优先级：创建进程时候，就已经确定了优先级了，然后整个运⾏时间优先级都不会变化
    2.动态优先级：根据进程的动态变化调整优先级，⽐如如果进程运⾏时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升⾼其优先级，也就是随着时间的推移增加等待进程的优先级

    该算法也有两种处理优先级⾼的⽅法，⾮抢占式和抢占式：
      1.⾮抢占式：当就绪队列中出现优先级⾼的进程，运⾏完当前进程，再选择优先级⾼的进程。
      2.抢占式：当就绪队列中出现优先级⾼的进程，当前进程挂起，调度优先级⾼的进程运⾏。
      3.但是依然有缺点，可能会导致低优先级的进程永远不会运⾏

  6.多级反馈队列（Multilevel Feedback Queue）调度算法是「时间⽚轮转算法」和「最⾼优先级算法」的综合和发展。
     「多级」表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短。
     「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列
    如何工作：
      1.设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短；
      2.新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间⽚没运⾏完成，则将其转⼊到第⼆级队列的末尾，以此类推，直⾄完成
      3.当较⾼优先级的队列为空，才调度较低优先级的队列中的进程运⾏。如果进程运⾏时，有新进程进⼊较⾼优先级的队列，则停⽌当前运⾏的进程并将其移⼊到原队列末尾，接着让较⾼优先级的进程运⾏；

进程间通信？
  管道、消息队列、共享内存、信号量、信号、socket
  1.通信的⽅式是单向的，数据只能在⼀个⽅向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能⽤于存在⽗⼦关系的进程间通信，匿名管道的⽣命周期随着进程创建⽽建⽴，随着进程终⽌⽽消失。
命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使⽤命名管道的前提，需要在⽂件系统创建⼀个类型为 p 的设备⽂件，那么毫⽆关系的进程就可以通过这个设备⽂件进⾏通信。另外，不管是匿名管道还是命名管道，进程写⼊的数据都是缓存在内核中，另⼀个进程读取数据时候⾃然也是从内核中获取，同时通信数据都遵循先进先出原则，不⽀持
lseek 之类的⽂件定位操作。
  2.消息队列克服了管道通信的数据是⽆格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以⽤户⾃定义的数据类型，发送数据时，会被分成⼀个⼀个独⽴的消息体，当然接收数据时，也要与发送⽅发送的消息体的数据类型保持⼀致，这样才能保证读取的数据是正确的。
消息队列通信的速度不是最及时的，毕竟每次数据的写⼊和读取都需要经过⽤户态与内核态之间的拷⻉过程.
  3.共享内存可以解决消息队列通信中⽤户态与内核态之间数据拷⻉过程带来的开销，它直接分配⼀个共享空间，每个进程都可以直接访问，就像访问进程⾃⼰的空间⼀样快捷⽅便，不需要陷⼊内核态或者系统调⽤，⼤⼤提⾼了通信的速度，享有最快的进程间通信⽅式之名。但是便捷⾼效的共享内存通信，带来新的问题，
多进程竞争同个共享资源会造成数据的错乱。
  4.⽅式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是⼀个计数器，表示的是资源个数，其值可以通过两个原⼦操作来控制，分别是P 操作和 V 操作。
  5.与信号量名字很相似的叫信号，它俩名字虽然相似，但功能⼀点⼉都不⼀样。信号是进程间通信机制中唯⼀的异步通信机制，信号可以在应⽤进程和内核之间直接交互，内核也可以利⽤信号来通知⽤户空间的进程发⽣了哪些系统事件，
信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），⼀旦有信号发⽣，进程有三种⽅式响应信号 1. 执⾏默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应⽤进程⽆法捕捉和忽略的，即
SIGKILL和SEGSTOP，这是为了⽅便我们能在任何时候结束或停⽌某个进程。


互斥和同步的概念：
   互斥（mutualexclusion)的，也就说保证⼀个线程在临界区执⾏时，其他线程应该被阻⽌进⼊临界区，说⽩了，就是这段代码执⾏过程中，最多只能出现⼀个线程。
   同步：所谓同步，就是并发进程/线程在⼀些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。

    操作系统必须提供实现进程协作的措施和⽅法，主要的⽅法有两种：1.锁：加锁、解锁操作； 2.信号量：P、V 操作；
这两个都可以⽅便地实现进程/线程互斥，⽽信号量⽐锁的功能更强⼀些，它还可以⽅便地实
现进程/线程同步。

锁？
  任何想进⼊临界区的线程，必须先执⾏加锁操作。若加锁操作顺利通过，则线程可进⼊临界区；在完成对临界资源的访问后再执⾏解锁操作，以释放该临界资源。

互斥锁和自旋锁的区别？
    互斥锁和自旋锁是最底层的两种锁，其他的很多锁都是基于他们的实现。当线程A获取到锁后，线程B再去获取锁，有两种处理方式，第一种是线程B循环的去尝试获取锁，
 直到获取成功为止即自旋锁，另一种是线程B放弃获取锁，在锁空闲时，等待被唤醒，即互斥锁。
	互斥锁加锁流程：
	   (1) 当线程加锁失败，内核会把线程的状态由“运行”设置为“睡眠”，让出cpu；
	   (2) 当锁空闲时，内核唤醒线程，状态设置为“就绪”，获取cpu执行；

  而自旋锁会自用户态由应用程序完成，不涉及用户态到内核态的转化，没有线程上下文切换，性能相对较好。自旋锁加锁过程：
     自旋锁加锁流程：
        (1) 查看锁的状态；
        (2) 锁空闲，获取锁，否则执行(1)；

   自旋锁会利用cpu一直工作直到获取到锁，中间不会释放cpu，但如果被锁住的代码执行时间较长，导致cpu空转，浪费资源。

两种锁适用于不同场景：
     1.如果是多核处理器，如果预计线程等待锁的时间很短，短到比线程两次上下文切换时间要少的情况下，使用自旋锁是划算的。
     2.如果是多核处理器，如果预计线程等待锁的时间较长，至少比两次线程上下文切换的时间要长，建议使用互斥量。
     3.如果是单核处理器，一般建议不要使用自旋锁。因为，在同一时间只有一个线程是处在运行状态，那如果运行线程发现无法获取锁，
       只能等待解锁，但因为自身不挂起，所以那个获取到锁的线程没有办法进入运行状态，只能等到运行线程把操作系统分给它的时间片用完，
       才能有机会被调度。这种情况下使用自旋锁的代价很高。

信号量
   信号量是操作系统提供的⼀种协调共享资源访问的⽅法,通常信号量表示资源的数量，对应的变量是⼀个整型（ sem ）变量
另外，还有两个原⼦操作的系统调⽤函数来控制信号量的，分别是：
  1.P 操作：将 sem 减 1 ，相减后，如果 sem < 0 ，则进程/线程进⼊阻塞等待，否则继 续，表明 P 操作可能会阻塞；
  2.V 操作：将 sem 加 1 ，相加后，如果 sem <= 0 ，唤醒⼀个等待中的进程/线程，表明V 操作不会阻塞

信号量实现临界区的互斥访问?
   任何想进⼊临界区的线程，必先在互斥信号量上执⾏ P 操作，在完成对临界资源的访问后再执⾏ V 操作。由于互斥信号量的初始值为 1，
故在第⼀个线程执⾏ P 操作后 s 值变为0，表示临界资源为空闲，可分配给该线程，使之进⼊临界区.若此时⼜有第⼆个线程想进⼊临界区，
也应先执⾏ P 操作，结果使 s 变为负值，这就意味着临界资源已被占⽤，因此，第⼆个线程被阻塞。
并且，直到第⼀个线程执⾏ V 操作，释放临界资源⽽恢复 s 值为 0 后，才唤醒第⼆个线程，使之进⼊临界区，待它完成临界资源的访问后，
⼜执⾏ V 操作，使 s 恢复到初始值 1。

对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示：
  1.如果互斥信号量为 1，表示没有线程进⼊临界区；
  2.如果互斥信号量为 0，表示有⼀个线程进⼊临界区；
  3.如果互斥信号量为 -1，表示⼀个线程进⼊临界区，另⼀个线程等待进⼊。
  通过互斥信号量的⽅式，就能保证临界区任何时刻只有⼀个线程在执⾏，就达到了互斥的效果。

信号量实现事件同步: 同步的⽅式是设置⼀个信号量，其初值为 0
  1.妈妈⼀开始询问⼉⼦要不要做饭时，执⾏的是 P(s1) ，相当于询问⼉⼦需不需要吃饭，由于s1 初始值为 0，此时 s1 变成 -1，
表明⼉⼦不需要吃饭，所以妈妈线程就进⼊等待状态。
  2.当⼉⼦肚⼦饿时，执⾏了 V(s1) ，使得 s1 信号量从 -1 变成 0，表明此时⼉⼦需要吃饭了，于是就唤醒了阻塞中的妈妈线程，妈妈线程就开始做饭
  3.接着，⼉⼦线程执⾏了 P(s2) ，相当于询问妈妈饭做完了吗，由于 s2 初始值是 0，则此时s2 变成 -1，说明妈妈还没做完饭，⼉⼦线程就等待状态
  4.最后，妈妈终于做完饭了，于是执⾏ V(s2) ， s2 信号量从 -1 变回了 0，于是就唤醒等待中的⼉⼦线程，唤醒后，⼉⼦线程就可以进⾏吃饭了。

死锁
   1.死锁的概念；
   2.模拟死锁问题的产⽣；
   3.利⽤⼯具排查死锁问题；
   4.避免死锁问题的发⽣

死锁的产生: 当两个线程为了保护两个不同的共享资源⽽使⽤了两个互斥锁，那么这两个互斥锁应⽤不当的时候，可能会造成两个线程都在等待对⽅释放锁，
在没有外⼒的作⽤下，这些线程会⼀直相互等待，就没办法继续运⾏，这种情况就是发⽣了死锁。

死锁只有同时满⾜以下四个条件才会发⽣：
  1.互斥条件 (互斥条件是指多个线程不能同时使⽤同⼀个资源)
  2.持有并等待条件 (当线程 A 已经持有了资源 1，⼜想申请资源 2，⽽资源 2 已经被线程C 持有了，
                    所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放⾃⼰已经持有的资源 1。)
  3.不可剥夺条件
  4.环路等待条件   (在死锁发⽣的时候，两个线程获取资源的顺序构成了环形链)
                    :线程 A 已经持有资源 2，⽽想请求资源 1， 线程 B 已经获取了资源 1，⽽想请求资源2，这就形成资源请求等待的环形图。


悲观锁与乐观锁

互斥锁与⾃旋锁：谁更轻松⾃如？
    当已经有⼀个线程加锁后，其他线程加锁则就会失败，互斥锁和⾃旋锁对于加锁失败后的处理⽅式是不⼀样的：
    1.互斥锁加锁失败后，线程会释放 CPU ，给其他线程。
    2.⾃旋锁加锁失败后，线程会忙等待，直到它拿到锁。

互斥锁是⼀种「独占锁」，⽐如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只
    要线程 A 没有释放⼿中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既
    然线程 B 释放掉了 CPU，⾃然线程 B 加锁的代码就会被阻塞。(对于互斥锁加锁失败⽽阻塞的现象，是由操作系统内核实现的),
    。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后,于是就可以继续执⾏。

互斥锁加锁失败会存在一定的性能损耗(会有2次的线程上下文切换)
    1.当线程加锁失败时，内核会把线程的状态从「运⾏」状态设置为「睡眠」状态，然后把CPU 切换给其他线程运⾏。
    2.接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运⾏。

线程的上下⽂切换的是什么？
   当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时,虚拟内存这些资源就保持不动,只需要切换线程的私有数据、寄存器等不共享的数据。
(上下切换的耗时有⼤佬统计过，⼤概在⼏⼗纳秒到⼏微秒之间，如果你锁住的代码执⾏时间⽐较短，那可能上下⽂切换的时间都⽐你锁住的代码执⾏时间还要⻓。)
所以，如果你能确定被锁住的代码执⾏时间很短，就不应该⽤互斥锁，⽽应该选⽤⾃旋锁，否则使⽤互斥锁。


自旋锁
   ⾃旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「⽤户态」完成加锁和解锁操作，
不会主动产⽣线程上下⽂切换，所以相⽐互斥锁来说，会快⼀些，开销也⼩⼀些。
  ⼀般加锁的过程，包含两个步骤：
    1.第⼀步，查看锁的状态，如果锁是空闲的，则执⾏第⼆步
    2.第⼆步，将锁设置为当前线程持有；
CAS 函数就把这两个步骤合并成⼀条硬件级指令，形成原⼦指令，这样就保证了这两个步骤是不可分割的，要么⼀次性执⾏完两个步骤，要么两个步骤都不执⾏。

  使⽤⾃旋锁的时候，当发⽣多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁,这⾥的「忙等待」可以⽤ while 循环等待实现，不过最好是使⽤ CPU 提供的
PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。

  ⾃旋锁是最⽐较简单的⼀种锁，⼀直⾃旋，利⽤ CPU 周期，直到锁可⽤。需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断⼀个线程，运⾏其他线程）.
否则，⾃旋锁在单 CPU 上⽆法使⽤，因为⼀个⾃旋的线程永远不会放弃 CPU。
  ⾃旋锁开销少，在多核系统下⼀般不会主动产⽣线程切换，适合异步、协程等在⽤户态切换请求的编程⽅式，但如果被锁住的代码执⾏时间过⻓，
⾃旋的线程会⻓时间占⽤ CPU 资源，所以⾃旋的时间和被锁住的代码执⾏的时间是成「正⽐」的关系，我们需要清楚的知道这⼀点。

  ⾃旋锁与互斥锁使⽤层⾯⽐较相似，但实现层⾯上完全不同：当加锁失败时，互斥锁⽤「线程切换」来应对，⾃旋锁则⽤「忙等待」来应对。
它俩是锁的最基本处理⽅式，更⾼级的锁都会选择其中⼀个来实现，⽐如读写锁既可以选择
互斥锁实现，也可以基于⾃旋锁实现。

  读写锁：读和写还有优先级区分？
  读写锁从字⾯意思我们也可以知道，它由「读锁」和「写锁」两部分构成,如果只读取共享
资源⽤「读锁」加锁，如果要修改共享资源则⽤「写锁」加锁。所以，读写锁适⽤于能明确区分读操作和写操作的场景

读写锁的⼯作原理是：
  1.当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这⼤⼤提⾼了共享资源的访问效率，因为「读锁」是⽤于读取共享资源的场景，
所以多个线程同时持有读锁也不会破坏共享资源的数据。
  2.但是，⼀旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，⽽且其他写线程的获取写锁的操作也会被阻塞。

所以说，写锁是独占锁，因为任何时刻只能有⼀个线程持有写锁，类似互斥锁和⾃旋锁，⽽读锁是共享锁，因为读锁可以被多个线程同时持有。
知道了读写锁的⼯作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。

读写锁可以分为「读优先锁」和「写优先锁」
   读优先锁：读锁能被更多的线程持有，以便提⾼读线程的并发性，它的⼯作⽅式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程
中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程B 才可以成功获取写锁。
   写优先锁：写优先锁是优先服务写线程，其⼯作⽅式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，
后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获
取读锁。
   读优先锁对于读线程并发性更好，但也不是没有问题。我们试想⼀下，如果⼀直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象


锁总结：
    开发过程中，最常⻅的就是互斥锁的了，互斥锁加锁失败时，会⽤「线程切换」来应对，当
加锁失败的线程再次加锁成功后的这⼀过程，会有两次线程上下⽂切换的成本，性能损耗⽐
较⼤.
   如果我们明确知道被锁住的代码的执⾏时间很短，那我们应该选择开销⽐较⼩的⾃旋锁，因
为⾃旋锁加锁失败时，并不会主动产⽣线程切换，⽽是⼀直忙等待，直到获取到锁，那么如
果被锁住的代码执⾏时间很短，那这个忙等待的时间相对应也很短。

   如果能区分读操作和写操作的场景，那读写锁就更合适了，它允许多个读线程可以同时持有
读锁，提⾼了读的并发性。根据偏袒读⽅还是写⽅，可以分为读优先锁和写优先锁，读优先
锁并发性很强，但是写线程会被饿死，⽽写优先锁会优先服务写线程，读线程也可能会被饿
死，那为了避免饥饿的问题，于是就有了公平读写锁，它是⽤队列把请求锁的线程排队，并
保证先⼊先出的原则来对线程加锁，这样便保证了某种线程不会被饿死，通⽤性也更好点
  另外，互斥锁、⾃旋锁、读写锁都属于悲观锁，悲观锁认为并发访问共享资源时，冲突概率
可能⾮常⾼，所以在访问共享资源前，都需要先加锁。



进程调度算法
   进程三大调度算法分别是，进程调度、页面置换、磁盘调度算法
什么情况会发生cpu调度？
   1.当进程从运⾏状态转到等待状态；
   2.当进程从运⾏状态转到就绪状态；
   3.当进程从等待状态转到就绪状态；
   4.当进程从运⾏状态转到终⽌状态；

其中发⽣在1和4两种情况下的调度称为「⾮抢占式调度」，2 和 3 两种情况下发⽣的调度称为「抢占式调度」。
    ⽽抢占式调度，顾名思义就是进程正在运⾏的时，可以被打断，使其把 CPU 让给其他进程。
那抢占的原则⼀般有三种，分别是时间⽚原则、优先权原则、短作业优先原则。
    假设有⼀个进程是处于等待状态的， 但是它的优先级⽐较⾼。如果该进程等待的事件发⽣了，它就会转到就绪状态，⼀旦它转到就绪状态
如果我们的调度算法是以优先级来进⾏调度的，那么它就会⽴⻢抢占正在运⾏的进程，所以这个时候就会发⽣ CPU调度。
    那第2种状态通常是时间⽚到的情况，因为时间⽚到了就会发⽣中断，于是就会抢占正在运⾏的进程，从⽽占⽤ CPU。

调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），⽽不能影响进程真在使⽤ CPU 的时间和 I/O 时间。

常见进程调度算法
    1.先来先服务调度算法
    2.最短作业优先调度算法
    3.⾼响应⽐优先调度算法
    4.时间⽚轮转调度算法
    5.最⾼优先级调度算法
    6.多级反馈队列调度算法

先来先服务调度算法：
   每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运⾏。

最短作业优先调度算法：
   最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运⾏时间最短的进程来运⾏，这有助于提⾼系统的吞吐量。
⾼响应⽐优先调度算法：

   前⾯的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和⻓作业，每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊
运⾏，「响应⽐优先级」的计算公式： 优先权 = (等待时间+要求服务的时间)/要求的服务时间
   1.如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越⾼，这样短作业的进程容易被选中运⾏；
   2.如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越⾼，这就兼顾到了⻓作业进程，因为进程的响应⽐可以随时间等待的增加⽽提⾼，当其等待时间⾜
     够⻓时，其响应⽐便可以升到很⾼，从⽽获得运⾏的机会；

 时间⽚轮转调度算法：
   最古⽼、最简单、最公平且使⽤最⼴的算法就是时间⽚轮转（Round Robin, RR）调度算法。
每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。
   1.如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配
另外⼀个进程；
   2.如果该进程在时间⽚结束前阻塞或结束，则 CPU ⽴即进⾏切换；
 另外，时间⽚的⻓度就是⼀个很关键的点：
   1.如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率
   2.如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓。将通常时间⽚设为 20ms~50ms 通常是⼀个⽐较合理的折中值。

最⾼优先级调度算法
  但是，对于多⽤户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度
程序能从就绪队列中选择最⾼优先级的进程进⾏运⾏，这称为最⾼优先级（Highest PriorityFirst，HPF）调度算法。

进程的优先级可以分为，静态优先级或动态优先级：
  1.静态优先级：创建进程时候，就已经确定了优先级了，然后整个运⾏时间优先级都不会变化；
  2.动态优先级：根据进程的动态变化调整优先级，⽐如如果进程运⾏时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升⾼其优先级，也就是随着时
    间的推移增加等待进程的优先级

该算法也有两种处理优先级⾼的⽅法，⾮抢占式和抢占式：
  1.⾮抢占式：当就绪队列中出现优先级⾼的进程，运⾏完当前进程，再选择优先级⾼的进程。
  2.抢占式：当就绪队列中出现优先级⾼的进程，当前进程挂起，调度优先级⾼的进程运⾏。
 但是依然有缺点，可能会导致低优先级的进程永远不会运⾏。

多级反馈队列调度算法？
  多级反馈队列（Multilevel Feedback Queue）调度算法是「时间⽚轮转算法」和「最⾼优先级算法」的综合和发展。
   1.「多级」表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短。
   2.「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列；

来看看，它是如何⼯作的：
   1.设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短;
   2.新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间⽚没运⾏完成，则将其转⼊到第⼆级队列的末尾，以此类推，直⾄完成；
   3.当较⾼优先级的队列为空，才调度较低优先级的队列中的进程运⾏。如果进程运⾏时，有新进程进⼊较⾼优先级的队列，则停⽌当前运⾏的进程并将其移⼊到原队列末尾，接着让较⾼优先级的进程运⾏；

   可以发现，对于短作业可能可以在第⼀级队列很快被处理完。对于⻓作业，如果在第⼀级队
列处理不完，可以移⼊下次队列等待被执⾏，虽然等待的时间变⻓了，但是运⾏时间也会更
⻓了，所以该算法很好的兼顾了⻓短作业，同时有较好的响应时间。


内存⻚⾯置换算法:
   缺⻚异常（缺⻚中断）处理流程：
   1.在 CPU ⾥访问⼀条 Load M 指令，然后 CPU 会去找 M 所对应的⻚表项。
   2.如果该⻚表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「⽆效的」，则 CPU 则会发送缺⻚中断请求。
   3.操作系统收到了缺⻚中断，则会执⾏缺⻚中断处理函数，先会查找该⻚⾯在磁盘中的⻚⾯的位置。
   4.找到磁盘中对应的⻚⾯后，需要把该⻚⾯换⼊到物理内存中，但是在换⼊前，需要在物理内存中找空闲⻚，如果找到空闲⻚，就把⻚⾯换⼊到物理内存中。
   5.⻚⾯从磁盘换⼊到物理内存完成后，则把⻚表项中的状态位修改为「有效的」。
   6.最后，CPU 重新执⾏导致缺⻚异常的指令。

上面第4步能在物理内存找到空闲页的情况，那如果找不到呢？
   找不到空闲⻚的话，就说明此时内存已满了，这时候，就需要「⻚⾯置换算法」选择⼀个物
理⻚，如果该物理⻚有被修改过（脏⻚），则把它换出到磁盘，然后把该被置换出去的⻚表
项的状态改成「⽆效的」，最后把正在访问的⻚⾯装⼊到这个物理⻚中

⻚表项:
   1.状态位：⽤于表示该⻚是否有效，也就是说是否在物理内存中，供程序访问时参考。
   2.访问字段：⽤于记录该⻚在⼀段时间被访问的次数，供⻚⾯置换算法选择出⻚⾯时参考。
   3.修改位：表示该⻚在调⼊内存后是否有被修改过，由于内存中的每⼀⻚都在磁盘上保留⼀
     份副本，因此，如果没有修改，在置换该⻚时就不需要将该⻚写回到磁盘上，以减少系统
     的开销；如果已经被修改，则将该⻚重写到磁盘上，以保证磁盘中所保留的始终是最新的
     副本。
   4.硬盘地址：⽤于指出该⻚在硬盘上的地址，通常是物理块号，供调⼊该⻚时使⽤


常⻅的⻚⾯置换算法有如下⼏种：
   1.最佳⻚⾯置换算法（OPT）
   2.先进先出置换算法（FIFO）
   3.最近最久未使⽤的置换算法（LRU）
   4.时钟⻚⾯置换算法（Lock）
   5.最不常⽤置换算法（LFU）

最佳⻚⾯置换算法:
   最佳⻚⾯置换算法基本思路是，置换在「未来」最⻓时间不访问的⻚⾯。
(所以，该算法实现需要计算内存中每个逻辑⻚⾯的「下⼀次」访问时间，然后⽐较，选择未来最⻓时间不访问的⻚⾯。)

先进先出置换算法:
   既然我们⽆法预知⻚⾯在下⼀次访问前所需的等待时间，那我们可以选择在内存驻留时间很
⻓的⻚⾯进⾏中置换，这个就是「先进先出置换」算法的思想。

最近最久未使⽤的置换算法:
   最近最久未使⽤（LRU）的置换算法的基本思路是，发⽣缺⻚时，选择最⻓时间没有被访问
的⻚⾯进⾏置换，也就是说，该算法假设已经很久没有使⽤的⻚⾯很有可能在未来较⻓的⼀
段时间内仍然不会被使⽤。

  这种算法近似最优置换算法，最优置换算法是通过「未来」的使⽤情况来推测要淘汰的⻚
⾯，⽽ LRU 则是通过「历史」的使⽤情况来推测要淘汰的⻚⾯。

时钟⻚⾯置换算法
   那有没有⼀种即能优化置换的次数，也能⽅便实现的算法呢？
时钟⻚⾯置换算法就可以两者兼得，它跟 LRU 近似，⼜是对 FIFO 的⼀种改进。
   该算法的思路是，把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⼀个表针指向最
⽼的⻚⾯。
  当发⽣缺⻚中断时，算法⾸先检查表针指向的⻚⾯
   1.如果它的访问位位是 0 就淘汰该⻚⾯，并把新的⻚⾯插⼊这个位置，然后把表针前移⼀个位置；
   2.如果访问位是 1 就清除访问位，并把表针前移⼀个位置，重复这个过程直到找到了⼀个访问位为 0 的⻚⾯为⽌；

最不常⽤算法
  当发⽣缺⻚中断时，选择「访问次数」最少的那个⻚⾯，并将其淘汰.
它的实现⽅式是，对每个⻚⾯设置⼀个「访问计数器」，每当⼀个⻚⾯被访问时，该⻚⾯的访问计数器就累加 1。在发⽣缺⻚中断时，淘汰计数器值最⼩的那个⻚⾯。
( 但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，⽐如有些⻚⾯在过去时间⾥访问的频率很⾼，但是现在已经没有访问了，
  ⽽当前频繁访问的⻚⾯由于没有这些⻚⾯访问的次数⾼，在发⽣缺⻚中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不⾼的⻚⾯
  那这个问题的解决的办法还是有的，可以定期减少访问的次数，⽐如当发⽣时间中断时，把过去时间访问的⻚⾯的访问次数除以 2，也就说，随着时间的流失，以前
  的⾼访问次数的⻚⾯会慢慢减少，相当于加⼤了被置换的概率。)


常见磁盘调度算法有哪些？
  1.先来先服务算法
    先来先服务，顾名思义，先到来的请求，先被服务。(请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过⻓。)

  2.最短寻道时间优先算法
    最短寻道时间优先（Shortest Seek First，SSF）算法的⼯作⽅式是，优先选择从当前磁头位置所需寻道时间最短的请求,还是以这个序列为例⼦：
98，183，37，122，14，124，65，67  那么，那么根据距离磁头（ 53 位置）最近的请求的算法，具体的请求则会是下列从左到右的顺序：
65，67，37，14，98，122，124，183 ,但但这个算法可能存在某些请求的饥饿，如果后续来的请求都是⼩于 183磁道的，那么 183 磁道可能永远不会被响应，于是就产⽣了饥饿现象。

  3.扫描算法算法
    最短寻道时间优先算法会产⽣饥饿的原因在于：磁头有可能再⼀个⼩区域内来回得移动，为了防⽌这个问题，可以规定：磁头在⼀个⽅向上移动，访问所有未完成的请求，
直到磁头到达该⽅向上的最后的磁道，才调换⽅向，这就是扫描（Scan）算法，⽐如电梯保持按⼀个⽅向移动，直到在那个⽅向上没有请求为⽌，然后改变⽅向。

  4.循环扫描算法
    循环扫描（Circular Scan, CSCAN ）规定：只有磁头朝某个特定⽅向移动时，才处理磁道访
问请求，⽽返回时直接快速移动⾄最靠边缘的磁道，也就是复位磁头，这个过程是很快的，
并且返回中途不处理任何请求，该算法的特点，就是磁道只响应⼀个⽅向上的请求

  5.LOOK 与 C-LOOK 算法
    那针对 SCAN 算法的优化则叫 LOOK 算法，它的⼯作⽅式，磁头在每个⽅向上仅仅移动到最
远的请求位置，然后⽴即反向移动，⽽不需要移动到磁盘的最始端或最末端，反向移动的途
中会响应请求
   ⽽针 C-SCAN 算法的优化则叫 C-LOOK，它的⼯作⽅式，磁头在每个⽅向上仅仅移动到最远
的请求位置，然后⽴即反向移动，⽽不需要移动到磁盘的最始端或最末端，反向移动的途中
不会响应请求。


文件系统